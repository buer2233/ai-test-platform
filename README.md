# AI自动化测试平台

> 一款功能强大的自动化测试平台，支持 API 自动化测试和 UI 自动化测试。提供完整的测试流程管理、断言配置、数据驱动测试和实时执行监控。

![Version](https://img.shields.io/badge/version-2.3-blue)
![Status](https://img.shields.io/badge/status-production--ready-green)
![License](https://img.shields.io/badge/license-MIT-orange)

## 目录

- [项目简介](#项目简介)
- [OpenSpec 开发规范](#openspec-开发规范)
- [核心功能](#核心功能)
- [快速开始](#快速开始)
- [使用指南](#使用指南)
- [功能详解](#功能详解)
- [最佳实践](#最佳实践)
- [常见问题](#常见问题)

---

## 项目简介

AI自动化测试平台是一款基于 **Django + Vue 3** 的前后端分离自动化测试解决方案。

### 模块架构

平台包含三个核心模块，当前 **API 自动化模块已 100% 完成**，**UI 自动化模块正在开发中**：

| 模块 | 状态 | 说明 |
|------|------|------|
| **API 自动化测试** | ✅ 100% 完成 | HTTP 接口测试、断言配置、数据驱动测试 |
| **UI 自动化测试** | 🚧 开发中 | 基于 browser_use 的 AI 驱动 UI 测试 |
| **AI 自动化测试** | ⚪ 规划中 | 智能测试生成和缺陷预测 |

### 适用场景

- **接口回归测试**：快速验证API功能正确性
- **接口性能监控**：实时监控接口响应时间
- **数据驱动测试**：使用多组数据批量测试接口
- **环境切换测试**：一键切换不同测试环境
- **团队协作测试**：共享测试项目和用例

---

## OpenSpec 开发规范

本项目使用 **OpenSpec** 进行规范驱动开发，确保所有新功能开发、重大变更、架构调整都有明确的规格说明和实施计划。

### 什么是 OpenSpec？

OpenSpec 是一个规范驱动开发工具，帮助团队：
- 在编码前明确需求规格
- 保持代码与规格同步
- 追踪变更历史和决策

### OpenSpec 工作流

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│  1. 创建提案      │ -> │  2. 实施变更      │ -> │  3. 归档变更      │
│  (proposal)      │    │  (apply)         │    │  (archive)       │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
        v                       v                       v
 openspec/changes/      编写代码               changes/archive/
  [change-id]/          更新 tasks.md          YYYY-MM-DD-[name]/
   proposal.md          完成测试               更新 specs/
   tasks.md
   specs/
```

### 何时需要创建 OpenSpec 提案

| 场景 | 是否需要提案 | 说明 |
|------|-------------|------|
| 新功能开发 | 是 | 需要创建 proposal.md 和规格增量 |
| 破坏性变更 (API/Schema) | 是 | 需要明确变更内容和迁移方案 |
| 架构调整 | 是 | 需要设计文档 (design.md) |
| 性能优化 (改变行为) | 是 | 需要说明优化理由和影响 |
| 安全更新 | 是 | 需要说明安全问题和修复方案 |
| Bug 修复 | 否 | 直接修复即可 |
| 拼写/格式修复 | 否 | 直接修复即可 |
| 非破坏性依赖更新 | 否 | 直接更新即可 |
| 测试添加 | 否 | 直接添加即可 |

### OpenSpec 命令速查

```bash
# 查看活跃的变更
openspec list

# 查看规格列表
openspec list --specs

# 查看详情
openspec show [item]

# 验证变更
openspec validate [change-id] --strict

# 归档变更
openspec archive <change-id> --yes
```

### OpenSpec 技能 (CLI 命令)

| 命令 | 描述 |
|------|------|
| `/openspec:proposal` | 创建新的 OpenSpec 变更提案 |
| `/openspec:apply` | 实施已批准的 OpenSpec 变更 |
| `/openspec:archive` | 归档已部署的 OpenSpec 变更 |

### 相关文档

- `openspec/AGENTS.md` - 完整的 OpenSpec 指令
- `openspec/project.md` - 项目上下文和约定
- `project_info.md` - 项目详细说明

---

## 核心功能

### 测试管理
- [x] **项目管理**：创建测试项目，组织测试资源
- [x] **集合管理**：按业务模块分组管理接口
- [x] **接口测试**：可视化编辑接口测试
- [x] **环境管理**：多环境配置，一键切换

### 测试执行
- [x] **HTTP执行器**：快速测试单个接口
- [x] **批量执行**：按集合/环境批量执行
- [x] **实时监控**：WebSocket实时推送执行状态
- [x] **断言验证**：11种断言类型，13种操作符
- [x] **数据提取**：6种提取方式，支持关联测试

### 数据驱动
- [x] **多数据源**：支持JSON、CSV、Excel、数据库
- [x] **变量映射**：灵活配置测试数据
- [x] **数据预览**：实时预览测试数据

### 报告分析
- [x] **多维度报告**：环境维度、集合维度
- [x] **可视化图表**：ECharts图表展示
- [x] **报告导出**：PDF、Excel、CSV、JSON、图片
- [x] **趋势分析**：历史测试趋势对比

---

## 快速开始

### 环境要求

**后端环境**
- Python 3.9+
- MySQL 8.0+ (或 SQLite 用于开发)

**前端环境**
- Node.js 16+
- npm 或 yarn

### 安装步骤

#### 1. 克隆项目

```bash
git clone https://github.com/your-org/ai-test-platform.git
cd ai-test-platform
```

#### 2. 后端安装

```bash
# 进入后端目录
cd Django_project

# 安装依赖
pip install -r requirements.txt

# 执行数据库迁移
python manage.py migrate

# 创建管理员账户
python manage.py createsuperuser

# 启动后端服务
python manage.py runserver
```

后端服务启动后，访问：
- API服务：http://127.0.0.1:8000/
- API文档：http://127.0.0.1:8000/swagger/

#### 3. 前端安装

```bash
# 进入前端目录
cd VUE3

# 安装依赖
npm install

# 启动开发服务
npm run dev
```

前端服务启动后，访问：http://localhost:3000/

#### 4. 登录系统

使用创建的管理员账户登录系统，开始使用。

---

## 使用指南

### 基础概念

```
项目 (Project)
    ├─ 环境配置 (Environment)
    ├─ 接口集合 (Collection)
    │   └─ 接口测试 (TestCase)
    │       ├─ 断言配置 (Assertion)
    │       └─ 数据提取 (Extraction)
    └─ 执行记录 (Execution)
        └─ 测试报告 (Report)
```

### 快速上手流程

#### 步骤1：创建测试项目

1. 登录后进入「项目管理」页面
2. 点击「新建项目」按钮
3. 填写项目信息：
   - **项目名称**：例如 "用户中心API测试"
   - **项目描述**：描述测试范围
   - **负责人**：选择负责人
4. 点击「确定」创建项目

#### 步骤2：配置测试环境

1. 进入「环境管理」页面
2. 点击「新建环境」
3. 配置环境信息：
   ```
   环境名称：测试环境
   基础URL：https://api.test.com
   全局请求头：
   - Content-Type: application/json
   - Authorization: Bearer {{token}}
   全局变量：
   - token: your-test-token
   ```
4. 保存并设为默认环境

#### 步骤3：创建接口集合

1. 进入项目详情页
2. 点击「集合管理」
3. 创建集合：
   - **集合名称**：例如 "用户模块"
   - **所属项目**：选择刚创建的项目
4. 保存集合

#### 步骤4：创建测试用例

**方式一：从HTTP执行器快速创建**

1. 进入「HTTP执行器」页面
2. 配置请求信息：
   - **方法**：POST
   - **URL**：/api/user/login
   - **请求头**：添加必要的请求头
   - **请求体**：
     ```json
     {
       "username": "testuser",
       "password": "123456"
     }
     ```
3. 点击「发送请求」
4. 验证响应结果后，点击「保存为用例」

**方式二：在接口管理页面创建**

1. 进入「接口测试」页面
2. 点击「新建接口」
3. 填写接口信息并配置断言
4. 保存接口

#### 步骤5：配置断言

断言用于验证接口响应是否符合预期。

**常用断言配置示例**

1. **状态码断言**
   - 类型：`status_code`
   - 操作符：`equals`
   - 期望值：`200`

2. **响应时间断言**
   - 类型：`response_time`
   - 操作符：`less_than`
   - 期望值：`1000` (毫秒)

3. **JSON值断言**
   - 类型：`json_value`
   - JSONPath：`$.code`
   - 操作符：`equals`
   - 期望值：`0`

4. **响应体包含断言**
   - 类型：`text_contains`
   - 操作符：`contains`
   - 期望值：`"success"`

#### 步骤6：数据提取配置

数据提取用于从响应中提取数据，供后续接口使用。

**提取配置示例**

1. **提取Token**
   - 提取类型：`json_path`
   - 提取表达式：`$.data.token`
   - 变量名：`login_token`
   - 作用域：`global` (全局变量)

2. **提取用户ID**
   - 提取类型：`json_path`
   - 提取表达式：`$.data.user.id`
   - 变量名：`user_id`
   - 作用域：`local` (局部变量)

提取后可在后续接口中使用：`${login_token}`

#### 步骤7：执行测试

**单个用例执行**

1. 进入测试用例列表
2. 点击用例右侧的「执行」按钮
3. 查看实时执行结果

**批量执行（按集合）**

1. 进入集合详情页
2. 选择要执行的环境
3. 点击「执行测试」按钮
4. 在实时监控页面查看执行进度

**批量执行（按环境）**

1. 进入仪表盘页面
2. 选择环境维度的环境
3. 点击「一键执行」
4. 查看执行结果

#### 步骤8：查看测试报告

1. 执行完成后进入「执行记录」
2. 点击查看详情
3. 查看测试报告：
   - 执行摘要（总数、通过数、失败数）
   - 失败用例列表
   - 响应时间图表
   - 详细结果

---

## 功能详解

### 变量系统

平台支持4种变量类型，方便灵活配置测试数据。

#### 变量类型

| 变量类型 | 语法格式 | 作用域 | 示例 |
|---------|---------|--------|------|
| 环境变量 | `${env.base_url}` | 当前环境 | 请求基础URL |
| 全局变量 | `${global.token}` | 所有测试 | 登录Token |
| 局部变量 | `${local.user_id}` | 当前用例 | 临时数据 |
| 提取变量 | `${extract.user_id}` | 后续用例 | 前置接口提取 |

#### 变量使用示例

```json
// 请求URL
${env.base_url}/api/user/${local.user_id}

// 请求头
{
  "Authorization": "Bearer ${global.token}"
}

// 请求体
{
  "userId": "${extract.user_id}",
  "userName": "testuser"
}
```

### 断言引擎

#### 断言类型（11种）

| 类型 | 说明 | 适用场景 |
|------|------|----------|
| `status_code` | HTTP状态码 | 验证接口是否成功 |
| `response_time` | 响应时间 | 性能验证 |
| `response_body` | 响应体内容 | 简单内容验证 |
| `response_headers` | 响应头 | 验证头信息 |
| `json_value` | JSON字段值 | 精确字段验证 |
| `text_contains` | 文本包含 | 模糊内容验证 |
| `json_schema` | JSON Schema | 结构验证 |
| `full_json` | 完整JSON | 完整响应验证 |
| `json_array` | JSON数组 | 数组验证 |
| `array_length` | 数组长度 | 数量验证 |
| `is_empty` | 空值验证 | 可选字段验证 |

#### 操作符（13种）

| 操作符 | 说明 | 适用类型 |
|--------|------|----------|
| `equals` | 等于 | 所有 |
| `not_equals` | 不等于 | 所有 |
| `contains` | 包含 | 文本 |
| `not_contains` | 不包含 | 文本 |
| `greater_than` | 大于 | 数值 |
| `less_than` | 小于 | 数值 |
| `between` | 在范围内 | 数值 |
| `starts_with` | 以...开头 | 文本 |
| `ends_with` | 以...结尾 | 文本 |
| `matches` | 正则匹配 | 文本 |
| `exists` | 字段存在 | JSON |
| `is_null` | 为空 | 所有 |
| `is_not_null` | 不为空 | 所有 |

### 数据驱动测试

数据驱动测试允许使用多组数据执行同一个用例。

#### 配置步骤

1. 进入用例详情页
2. 切换到「数据驱动」标签
3. 选择数据源类型：
   - **JSON数据**：直接输入JSON数组
   - **CSV文件**：上传CSV文件
   - **Excel文件**：上传Excel文件
   - **数据库查询**：配置数据库连接和SQL

4. 配置变量映射
5. 预览数据
6. 保存配置

#### JSON数据示例

```json
[
  {
    "username": "user1",
    "password": "pass1",
    "expected": "success"
  },
  {
    "username": "user2",
    "password": "pass2",
    "expected": "success"
  },
  {
    "username": "user3",
    "password": "wrong_pass",
    "expected": "failed"
  }
]
```

#### 变量映射示例

```
username → ${data.username}
password → ${data.password}
expected → ${data.expected}
```

### HTTP执行器

HTTP执行器是快速测试接口的工具。

#### 功能特性

1. **请求配置**
   - 支持所有HTTP方法
   - 可视化配置请求头和参数
   - 支持多种请求体格式（JSON、Form、Multipart）

2. **变量替换**
   - 自动识别并高亮变量
   - 实时预览替换后的值

3. **响应查看**
   - 状态码和响应时间
   - 响应头和响应体
   - JSON格式化高亮

4. **快捷保存**
   - 一键保存为测试用例
   - 自动关联项目和集合

### cURL导入导出

#### 导入cURL

1. 在浏览器或Postman中复制cURL命令
2. 在HTTP执行器中点击「导入cURL」
3. 粘贴cURL命令
4. 系统自动解析并填充请求配置

#### 导出cURL

1. 配置好测试用例后
2. 点击「导出cURL」
3. 复制生成的cURL命令

### 环境管理

#### 环境配置要点

```
环境名称：开发环境
基础URL：https://api-dev.example.com

全局请求头：
  Content-Type: application/json
  Authorization: Bearer {{dev_token}}

全局变量：
  token: dev-token-12345
  api_key: dev-key-67890
```

#### 环境切换

1. 在测试执行时选择环境
2. 或设置默认环境自动使用
3. 所有`${env.*}`变量自动切换

### 实时执行监控

执行测试时可打开实时监控页面查看进度。

#### 监控功能

- **执行进度条**：显示总进度
- **实时日志**：显示每个用例的执行日志
- **响应时间图表**：ECharts实时绘制
- **快捷键支持**：
  - `Space`：暂停/继续
  - `Esc`：停止执行
  - `F`：全屏模式
  - `R`：重新执行
  - `C`：清空日志

---

## 最佳实践

### 用例组织

1. **按模块分组**：按业务模块创建集合
   ```
   用户模块
   ├─ 用户登录
   ├─ 用户注册
   ├─ 获取用户信息
   └─ 修改密码

   订单模块
   ├─ 创建订单
   ├─ 查询订单
   └─ 取消订单
   ```

2. **用例命名规范**
   - 使用动词开头：登录、查询、创建
   - 包含关键信息：登录_成功场景、查询_无效ID

3. **标签管理**：使用标签标识用例类型
   - `冒烟测试`：核心功能验证
   - `回归测试`：完整功能验证
   - `性能测试`：响应时间验证

### 断言配置建议

1. **必配断言**
   - HTTP状态码：验证接口可用
   - 业务状态码：验证业务成功

2. **重要字段断言**
   - 关键数据字段（如订单号）
   - 金额、数量等敏感字段

3. **性能断言**
   - 响应时间：根据实际需求设定
   - 建议：普通接口<1s，复杂接口<3s

### 数据提取策略

1. **提取时机**：从稳定的接口提取数据
   - 登录接口提取Token
   - 创建接口提取ID

2. **变量命名**
   - 使用有意义的名称
   - 遵循命名规范：`login_token`、`user_id`

3. **作用域选择**
   - 通用数据：全局作用域
   - 临时数据：局部作用域

### 环境配置技巧

1. **环境隔离**
   - 开发、测试、预发布、生产分开配置
   - 使用不同的基础URL

2. **变量复用**
   - 相同配置放在全局变量
   - 环境差异使用环境变量

3. **敏感信息**
   - Token等敏感信息使用变量
   - 定期更新敏感数据

---

## 常见问题

### Q1: 如何处理需要登录的接口？

**A**: 使用数据提取功能获取登录Token：

1. 创建登录用例
2. 配置JSONPath提取：`$.data.token`
3. 变量名设为`auth_token`，作用域设为`global`
4. 后续接口在请求头中使用：`${global.auth_token}`

### Q2: 如何进行关联测试（接口依赖）？

**A**: 使用数据提取和变量系统：

1. 第一个接口提取数据：
   - 提取类型：`json_path`
   - 表达式：`$.data.orderId`
   - 变量名：`order_id`

2. 第二个接口使用数据：
   - URL：`/api/order/${extract.order_id}`

### Q3: 如何在接口测试中测试分页接口？

**A**: 使用数据驱动测试：

```json
[
  {"page": 1, "size": 10},
  {"page": 2, "size": 10},
  {"page": 3, "size": 10}
]
```

变量映射：
```
page → ${data.page}
size → ${data.size}
```

### Q4: 断言失败如何排查？

**A**: 查看执行详情：

1. 点击执行记录
2. 查看失败的断言
3. 对比期望值和实际值
4. 查看完整响应内容
5. 调整断言配置或接口实现

### Q5: 如何批量导入测试用例？

**A**: 三种方式：

1. **从Postman导入**：使用Postman的cURL导出功能
2. **从Swagger导入**：参考Swagger文档手动创建
3. **Excel导入**：（待实现功能）

### Q6: 响应时间过慢怎么办？

**A**: 排查步骤：

1. 检查网络延迟
2. 检查服务器性能
3. 优化接口查询
4. 调整断言阈值
5. 考虑使用异步接口

### Q7: 如何分享测试用例？

**A**: 两种方式：

1. **克隆功能**：克隆项目/集合给其他成员
2. **导出功能**：导出配置（JSON格式）

### Q8: 测试数据如何管理？

**A**: 最佳实践：

1. 使用专用测试账号
2. 定期清理测试数据
3. 使用数据工厂自动生成
4. 环境隔离避免数据污染

---

## 技术支持

### 文档资源

**核心文档**
- [项目说明](./project_info.md) - 项目详细说明文档
- [UI项目需求](./ui_project_info.md) - UI自动化测试模块需求文档
- [OpenSpec 指令](./openspec/AGENTS.md) - OpenSpec 规范驱动开发指南
- [项目上下文](./openspec/project.md) - 项目约定和技术栈

**开发与测试**
- [开发文档](./develop_document/) - 功能设计和实现文档
- [测试用例](./test_case/) - 功能测试用例
- [API文档](http://127.0.0.1:8000/swagger/) - 后端API详细文档

### 问题反馈

- GitHub Issues：提交问题和建议
- 技术交流群：（待建立）

### 更新日志

#### v2.3 (2026-01-16)
- ✅ 设计系统实现 - 简约科技风格 (浅色主题)
- ✅ 用户注册功能 - 登录页面集成注册Tab
- ✅ 回收站功能 - 级联删除预览、恢复、彻底删除
- ✅ Playwright探索性测试 - 发现并修复6个错误
- ✅ 项目完整度100% - 15页面、24组件、12API模块

#### v2.2 (2025-12-25)
- ✅ 仪表盘数据统计修复
- ✅ 图表可视化 (柱状图、饼状图)
- ✅ 图表点击交互筛选
- ✅ WebSocket实时推送完整实现
- ✅ 报告导出功能 (PDF/Excel/CSV/JSON/图片)
- ✅ 批量操作界面
- ✅ 增强测试用例编辑器 (cURL导入/导出)

#### v2.1 (2025-12-24) - 设计阶段
- 🎯 **测试用例功能优化**（设计完成，待开发）
  - 串联执行+变量传递+断言: 支持多个测试用例按顺序执行，用例间可传递变量
  - 项目和集合关联: 增强测试集合管理，支持批量添加/移除用例
  - 三种批量执行方式: 按集合执行、按项目执行、手动选择执行
  - 数据分级存储+自动清理: HTTP 200仅存摘要，非200存完整数据；7天前数据每日2:00自动清理
  - 测试报告页面: 独立的报告列表和详情页，支持筛选、搜索、导出
  - 开发文档: `develop_document/09-测试用例功能优化.md` (v3.0)
  - 测试用例: `test_case/09-测试用例功能优化测试用例.md` (v2.0, 32个用例)

#### v2.0 (2025-12-24)
- ✅ 完成所有核心功能
- ✅ 报告导出功能（PDF/Excel/CSV/JSON/图片）
- ✅ 批量操作界面
- ✅ WebSocket实时推送
- ✅ 增强测试用例编辑器
- ✅ 全面功能测试通过（A+评级）

---

## 开源协议

本项目采用 [MIT](LICENSE) 开源协议。

---

**最后更新：2026-01-20**

**测试平台版本：v3.0 (UI自动化模块开发中)**

---

## UI自动化测试模块 (开发中)

基于 **browser_use** 开源框架的 AI 驱动 UI 自动化测试。用户通过自然语言描述测试场景，AI 自动理解并执行浏览器操作。

**核心特性**
- 自然语言驱动测试（无需编码）
- AI 智能执行（browser_use Agent）
- 实时执行监控（WebSocket 推送）
- 可视化测试报告（截图 + 时间线）

**项目路径**
- 需求文档：[ui_project_info.md](./ui_project_info.md)
- 后端：`Django_project/ui_automation/`
- 前端：`VUE3/src/modules/ui-automation/`
