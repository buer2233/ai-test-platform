# UI自动化通用执行脚本测试用例

> 创建日期：2026-01-21
> 版本：v1.0.0
> 测试范围：run_aiTest.py 脚本及后端 CLI 调用服务

---

## 一、测试概述

### 1.1 测试目标

验证 UI 自动化通用执行脚本的完整功能，包括：
1. 独立 CLI 模式执行测试
2. 后端 API 调用 CLI 执行测试
3. 实时进度推送
4. 测试报告生成和存储

### 1.2 测试环境

| 项目 | 值 |
|------|-----|
| 操作系统 | Windows |
| Python 版本 | 3.12 |
| Django 项目路径 | D:\AI\AI-test-project\Django_project |
| browser-use 路径 | D:\AI\AI-test-project\Django_project\ui_automation\browser-use-0.11.2 |
| 报告目录 | D:\AI\AI-test-project\Django_project\ui_automation\browser-use-0.11.2\report |

### 1.3 测试前置条件

1. Python 3.12 环境已安装
2. browser-use 已正确安装
3. .env 文件中已配置 OPENAI_API_KEY 和 OPENAI_API_BASE_URL
4. Django 后端服务可以正常启动

---

## 二、测试用例分类

### 2.1 单元测试：run_aiTest.py 脚本

| 用例ID | 测试项 | 优先级 |
|--------|--------|--------|
| TC-CLI-001 | CLI 参数解析 - 基础参数 | P0 |
| TC-CLI-002 | CLI 参数解析 - 所有参数 | P0 |
| TC-CLI-003 | CLI 参数解析 - 默认值 | P1 |
| TC-CLI-004 | CLI 参数解析 - 必填参数缺失 | P0 |
| TC-CLI-005 | 环境变量加载 - OPENAI_API_KEY | P0 |
| TC-CLI-006 | 环境变量加载 - OPENAI_API_BASE_URL | P0 |
| TC-CLI-007 | 报告目录创建 | P0 |
| TC-CLI-008 | 输出格式 - JSON 格式 | P0 |
| TC-CLI-009 | 输出格式 - Text 格式 | P1 |
| TC-CLI-010 | 进度输出格式 | P0 |
| TC-CLI-011 | 结果输出格式 | P0 |

### 2.2 集成测试：CLI 执行功能

| 用例ID | 测试项 | 优先级 |
|--------|--------|--------|
| TC-INT-001 | 简单搜索任务执行 | P0 |
| TC-INT-002 | 多步骤任务执行 | P0 |
| TC-INT-003 | 有头模式执行 | P0 |
| TC-INT-004 | 无头模式执行 | P0 |
| TC-INT-005 | 指定模型执行 | P1 |
| TC-INT-006 | 自定义最大步骤数 | P1 |
| TC-INT-007 | 任务执行超时处理 | P1 |
| TC-INT-008 | 任务执行失败处理 | P0 |
| TC-INT-009 | 报告文件生成 | P0 |
| TC-INT-010 | 报告文件内容验证 | P0 |

### 2.3 后端服务测试：CliTestExecutorService

| 用例ID | 测试项 | 优先级 |
|--------|--------|--------|
| TC-SVC-001 | 服务初始化 | P0 |
| TC-SVC-002 | subprocess 命令构建 | P0 |
| TC-SVC-003 | 进度输出解析 | P0 |
| TC-SVC-004 | 结果输出解析 | P0 |
| TC-SVC-005 | 进度回调触发 | P0 |
| TC-SVC-006 | 执行成功返回 | P0 |
| TC-SVC-007 | 执行失败返回 | P0 |
| TC-SVC-008 | 进程取消功能 | P1 |

### 2.4 API 集成测试

| 用例ID | 测试项 | 优先级 |
|--------|--------|--------|
| TC-API-001 | 执行接口调用 - 成功场景 | P0 |
| TC-API-002 | 执行接口调用 - 用例未启用 | P0 |
| TC-API-003 | 执行记录创建 | P0 |
| TC-API-004 | 执行状态更新 | P0 |
| TC-API-005 | 测试报告关联 | P0 |
| TC-API-006 | WebSocket 进度推送 | P0 |

### 2.5 端到端测试

| 用例ID | 测试项 | 优先级 |
|--------|--------|--------|
| TC-E2E-001 | 完整执行流程 - 成功场景 | P0 |
| TC-E2E-002 | 完整执行流程 - 失败场景 | P0 |
| TC-E2E-003 | 前端实时进度显示 | P0 |
| TC-E2E-004 | 前端报告展示 | P0 |

---

## 三、详细测试用例

### 3.1 单元测试：run_aiTest.py

#### TC-CLI-001: CLI 参数解析 - 基础参数

**测试描述**：验证脚本能够正确解析基础的 task 参数

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行命令：`python run_aiTest.py --task "测试任务"`
2. 检查脚本是否正常启动
3. 验证 task 参数是否正确传递

**预期结果**：
- 脚本正常启动，不报参数错误
- task 参数值正确传递给 AITestRunner

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-002: CLI 参数解析 - 所有参数

**测试描述**：验证脚本能够正确解析所有支持的参数

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行完整参数命令：
```bash
python run_aiTest.py \
  --task "搜索 browser-use" \
  --browser-mode headless \
  --model gpt-4o-mini \
  --max-steps 50 \
  --execution-id "test_001" \
  --output-format json \
  --timeout 180
```
2. 检查脚本是否正常启动
3. 验证所有参数是否正确传递

**预期结果**：
- 所有参数正确解析
- AITestRunner 使用正确的配置初始化

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-003: CLI 参数解析 - 默认值

**测试描述**：验证未指定参数时使用正确的默认值

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行命令：`python run_aiTest.py --task "测试"`
2. 检查使用的默认值：
   - browser_mode: headless
   - model: gpt-4o-mini
   - max_steps: 50
   - output_format: json

**预期结果**：
- 使用正确的默认值
- 脚本正常运行

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-004: CLI 参数解析 - 必填参数缺失

**测试描述**：验证缺少必填参数时的错误处理

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行命令：`python run_aiTest.py`（不带 task 参数）
2. 检查错误提示

**预期结果**：
- 显示错误信息，提示 task 参数必填
- 退出码非 0
- 显示帮助信息

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-005: 环境变量加载 - OPENAI_API_KEY

**测试描述**：验证从 .env 文件正确加载 OPENAI_API_KEY

**前置条件**：
- .env 文件已配置 OPENAI_API_KEY
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行简单测试命令
2. 检查是否能成功初始化 LLM

**预期结果**：
- 正确读取 OPENAI_API_KEY
- LLM 初始化成功

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-006: 环境变量加载 - OPENAI_API_BASE_URL

**测试描述**：验证从 .env 文件正确加载 OPENAI_API_BASE_URL

**前置条件**：
- .env 文件已配置 OPENAI_API_BASE_URL
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行简单测试命令
2. 检查 LLM 使用的 base_url

**预期结果**：
- 正确读取 OPENAI_API_BASE_URL
- LLM 使用正确的 base_url

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-007: 报告目录创建

**测试描述**：验证报告目录不存在时自动创建

**前置条件**：
- run_aiTest.py 脚本已创建
- 删除已存在的 report 目录

**测试步骤**：
1. 删除 report 目录（如果存在）
2. 执行测试命令
3. 检查 report 目录是否创建

**预期结果**：
- report 目录自动创建
- 测试报告文件保存成功

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-008: 输出格式 - JSON 格式

**测试描述**：验证 JSON 格式输出正确

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行命令：`python run_aiTest.py --task "测试" --output-format json`
2. 捕获输出
3. 验证输出格式

**预期结果**：
- 进度输出格式：`##PROGRESS##{json}`
- 结果输出格式：`##RESULT##{json}`
- JSON 可以正确解析

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-009: 输出格式 - Text 格式

**测试描述**：验证 Text 格式输出正确

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行命令：`python run_aiTest.py --task "测试" --output-format text`
2. 捕获输出
3. 验证输出格式

**预期结果**：
- 输出为人类可读的文本格式
- 不包含 JSON 标记

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-010: 进度输出格式

**测试描述**：验证进度输出符合规范

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行测试任务
2. 捕获进度输出
3. 解析并验证格式

**预期结果**：
- 进度输出格式：`##PROGRESS##{"timestamp": "...", "level": "info/error", "message": "...", "data": {...}}`
- timestamp 为 ISO 8601 格式
- level 为 info 或 error
- message 为描述性文本
- data 为可选的额外数据

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-CLI-011: 结果输出格式

**测试描述**：验证结果输出符合规范

**前置条件**：
- run_aiTest.py 脚本已创建

**测试步骤**：
1. 执行测试任务直到完成
2. 捕获结果输出
3. 解析并验证格式

**预期结果**：
- 结果输出格式：`##RESULT##{"success": true/false, "timestamp": "...", "duration_seconds": ..., "data": {...}}`
- success 为布尔值
- duration_seconds 为浮点数
- data 包含：execution_id, report_path, is_done, is_successful, total_steps, final_result

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

### 3.2 集成测试：CLI 执行功能

#### TC-INT-001: 简单搜索任务执行

**测试描述**：验证能够执行简单的搜索任务

**前置条件**：
- run_aiTest.py 脚本已创建并可用
- OPENAI_API_KEY 已配置

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开谷歌搜索 browser-use 并告诉我第一个结果的标题" --max-steps 20
```
2. 观察执行过程
3. 检查执行结果
4. 验证报告文件

**预期结果**：
- 任务成功执行
- 输出进度信息
- 生成报告文件
- 最终结果包含搜索结果

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-002: 多步骤任务执行

**测试描述**：验证能够执行复杂的多步骤任务

**前置条件**：
- run_aiTest.py 脚本已创建并可用
- OPENAI_API_KEY 已配置

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开谷歌，搜索 browser-use，点击第一个结果，然后告诉我页面标题" --max-steps 50
```
2. 观察执行过程
3. 检查执行步骤
4. 验证报告文件

**预期结果**：
- 任务成功执行
- 执行多个步骤（>3）
- 每个步骤都有进度输出
- 报告包含完整的历史记录

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-003: 有头模式执行

**测试描述**：验证有头模式下浏览器可见

**前置条件**：
- run_aiTest.py 脚本已创建并可用

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开百度首页" --browser-mode headed --max-steps 10
```
2. 观察浏览器窗口是否打开
3. 验证浏览器操作

**预期结果**：
- 浏览器窗口可见
- 可以观察到浏览器操作
- 任务成功执行

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-004: 无头模式执行

**测试描述**：验证无头模式下浏览器不可见

**前置条件**：
- run_aiTest.py 脚本已创建并可用

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开百度首页" --browser-mode headless --max-steps 10
```
2. 确认浏览器窗口不可见
3. 验证任务执行

**预期结果**：
- 浏览器窗口不可见
- 任务成功执行
- 报告正常生成

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-005: 指定模型执行

**测试描述**：验证使用指定的 LLM 模型

**前置条件**：
- run_aiTest.py 脚本已创建并可用
- 有多个可用的模型

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开百度首页" --model gpt-4o-mini --max-steps 10
```
2. 检查日志确认使用的模型

**预期结果**：
- 使用指定的模型
- 任务正常执行

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-006: 自定义最大步骤数

**测试描述**：验证自定义最大步骤数生效

**前置条件**：
- run_aiTest.py 脚本已创建并可用

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "搜索 browser-use 并告诉我前5个结果" --max-steps 15
```
2. 观察执行是否在 15 步内完成或停止

**预期结果**：
- 执行步骤不超过 max-steps
- 达到最大步骤时停止并返回结果

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-007: 任务执行超时处理

**测试描述**：验证单步超时处理

**前置条件**：
- run_aiTest.py 脚本已创建并可用

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "打开一个响应很慢的网站" --timeout 5 --max-steps 10
```
2. 观察超时处理

**预期结果**：
- 超时后继续执行下一步
- 输出超时错误信息
- 最终返回结果

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-008: 任务执行失败处理

**测试描述**：验证任务失败时的处理

**前置条件**：
- run_aiTest.py 脚本已创建并可用

**测试步骤**：
1. 执行命令：
```bash
python run_aiTest.py --task "访问一个不存在的网站 xyz123abc.com" --max-steps 10
```
2. 观察失败处理

**预期结果**：
- 捕获错误信息
- 输出错误日志
- 最终结果 success=false
- 仍然生成报告文件

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-009: 报告文件生成

**测试描述**：验证报告文件正确生成

**前置条件**：
- run_aiTest.py 脚本已创建并可用
- report 目录存在

**测试步骤**：
1. 执行测试任务
2. 检查 report 目录
3. 验证报告文件名

**预期结果**：
- 报告文件生成在 report/ 目录
- 文件名格式：{execution_id}.json
- 文件可以正常打开

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-INT-010: 报告文件内容验证

**测试描述**：验证报告文件内容完整

**前置条件**：
- run_aiTest.py 脚本已创建并可用
- 已生成报告文件

**测试步骤**：
1. 打开报告文件
2. 验证 JSON 结构
3. 检查关键字段

**预期结果**：
- JSON 格式正确
- 包含 history 数组
- 每个 history 项包含：model_output, result, state, metadata
- 包含 usage 信息（tokens、cost）

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

### 3.3 后端服务测试：CliTestExecutorService

#### TC-SVC-001: 服务初始化

**测试描述**：验证 CliTestExecutorService 正确初始化

**前置条件**：
- CliTestExecutorService 已创建
- 测试用例已创建

**测试步骤**：
1. 创建服务实例：
```python
service = CliTestExecutorService(
    execution_id=1,
    task="测试任务",
    browser_mode="headless",
    progress_callback=None
)
```
2. 检查属性值

**预期结果**：
- 所有属性正确设置
- SCRIPT_PATH 路径正确

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-002: subprocess 命令构建

**测试描述**：验证 subprocess 命令正确构建

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 创建服务实例
2. 检查内部构建的命令列表

**预期结果**：
- 命令包含 python 解释器
- 命令包含 run_aiTest.py 路径
- 命令包含所有必要的参数

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-003: 进度输出解析

**测试描述**：验证进度输出正确解析

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 调用 _parse_output_line("##PROGRESS##{\"level\":\"info\",\"message\":\"测试\"}")
2. 检查返回值

**预期结果**：
- 返回 {"type": "progress", "data": {...}}
- data 包含正确的 level 和 message

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-004: 结果输出解析

**测试描述**：验证结果输出正确解析

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 调用 _parse_output_line("##RESULT##{\"success\":true}")
2. 检查返回值

**预期结果**：
- 返回 {"type": "result", "data": {...}}
- data 包含正确的 success 值

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-005: 进度回调触发

**测试描述**：验证进度回调正确触发

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 创建一个 mock 回调函数
2. 创建服务实例并传入回调
3. 执行测试任务
4. 验证回调被调用

**预期结果**：
- 回调函数被多次调用
- 每次调用包含正确的数据结构

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-006: 执行成功返回

**测试描述**：验证执行成功时返回正确结果

**前置条件**：
- CliTestExecutorService 已创建
- 测试任务能够成功执行

**测试步骤**：
1. 执行简单测试任务
2. 获取返回结果

**预期结果**：
- 返回字典 success=true
- 包含 report_path
- 包含 total_steps
- 包含 is_successful=true

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-007: 执行失败返回

**测试描述**：验证执行失败时返回正确结果

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 执行一个会失败的任务（如错误的 API key）
2. 获取返回结果

**预期结果**：
- 返回字典 success=false
- 包含 error 信息
- 可能包含 stderr 输出

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-SVC-008: 进程取消功能

**测试描述**：验证能够取消正在执行的进程

**前置条件**：
- CliTestExecutorService 已创建

**测试步骤**：
1. 启动一个长时间运行的任务
2. 在任务执行中调用 cancel()
3. 检查进程是否终止

**预期结果**：
- 进程被终止
- 返回 True 表示取消成功
- 推送取消消息

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

### 3.4 API 集成测试

#### TC-API-001: 执行接口调用 - 成功场景

**测试描述**：验证执行接口正常工作

**前置条件**：
- Django 后端服务运行中
- 测试用例已创建
- 用户已登录

**测试步骤**：
1. 发送 POST 请求：
```
POST /api/v1/ui-automation/test-cases/{id}/execute/
Content-Type: application/json

{
  "browser_mode": "headless"
}
```
2. 检查响应

**预期结果**：
- 返回 201 Created
- 返回 UiTestExecution 序列化数据
- status=pending 或 running
- 包含 execution_id

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-API-002: 执行接口调用 - 用例未启用

**测试描述**：验证禁用用例不能执行

**前置条件**：
- Django 后端服务运行中
- 测试用例 is_enabled=False

**测试步骤**：
1. 对禁用用例发送执行请求
2. 检查响应

**预期结果**：
- 返回 400 Bad Request
- 包含错误信息

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-API-003: 执行记录创建

**测试描述**：验证执行记录正确创建

**前置条件**：
- Django 后端服务运行中
- 测试用例已创建

**测试步骤**：
1. 调用执行接口
2. 查询数据库中的 UiTestExecution 记录

**预期结果**：
- 创建了新的 UiTestExecution 记录
- test_case 外键正确
- browser_mode 正确
- status 初始为 pending
- created_by 正确

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-API-004: 执行状态更新

**测试描述**：验证执行状态正确更新

**前置条件**：
- Django 后端服务运行中
- 执行任务已启动

**测试步骤**：
1. 启动执行任务
2. 等待任务完成
3. 查询 UiTestExecution 记录

**预期结果**：
- status 更新为 passed 或 failed
- completed_at 有值
- duration_seconds 有值
- final_result 有值（成功时）
- error_message 有值（失败时）

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-API-005: 测试报告关联

**测试描述**：验证测试报告正确关联

**前置条件**：
- Django 后端服务运行中
- 执行任务已完成

**测试步骤**：
1. 执行测试任务
2. 等待完成
3. 查询 UiTestReport 记录

**预期结果**：
- 创建了 UiTestReport 记录
- execution 外键正确
- report_path 有值
- 指向正确的报告文件

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-API-006: WebSocket 进度推送

**测试描述**：验证 WebSocket 实时推送进度

**前置条件**：
- Django 后端服务运行中
- WebSocket 服务已配置

**测试步骤**：
1. 连接 WebSocket：`ws://127.0.0.1:8000/ws/ui-automation/{execution_id}/`
2. 调用执行接口
3. 监听 WebSocket 消息

**预期结果**：
- 接收到多条进度消息
- 消息格式正确
- 包含执行步骤信息

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

### 3.5 端到端测试

#### TC-E2E-001: 完整执行流程 - 成功场景

**测试描述**：验证从前端到后端到 CLI 的完整流程

**前置条件**：
- 前端服务运行中
- 后端服务运行中
- 用户已登录
- 测试用例已创建

**测试步骤**：
1. 前端进入测试用例详情页
2. 点击"执行测试"按钮
3. 选择浏览器模式
4. 确认执行
5. 观察执行过程
6. 等待执行完成
7. 查看测试报告

**预期结果**：
- 执行按钮点击后显示加载状态
- 跳转到执行监控页面
- 实时显示执行日志
- 执行完成后显示成功状态
- 可以查看测试报告

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-E2E-002: 完整执行流程 - 失败场景

**测试描述**：验证失败场景的处理

**前置条件**：
- 前端服务运行中
- 后端服务运行中
- 测试用例已创建

**测试步骤**：
1. 创建一个会失败的测试用例
2. 执行测试用例
3. 观察失败处理

**预期结果**：
- 显示失败状态
- 显示错误信息
- 仍然可以查看报告

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-E2E-003: 前端实时进度显示

**测试描述**：验证前端实时显示执行进度

**前置条件**：
- 前端服务运行中
- 后端服务运行中
- WebSocket 连接正常

**测试步骤**：
1. 执行一个多步骤测试任务
2. 观察执行监控页面
3. 检查进度更新

**预期结果**：
- 实时显示执行步骤
- 每个步骤有描述
- 显示执行时间
- 显示步骤状态

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

#### TC-E2E-004: 前端报告展示

**测试描述**：验证前端正确展示测试报告

**前置条件**：
- 前端服务运行中
- 后端服务运行中
- 测试已执行完成

**测试步骤**：
1. 进入测试报告页面
2. 点击某个报告
3. 查看报告详情

**预期结果**：
- 显示报告概览
- 显示执行步骤列表
- 每个步骤可展开查看详情
- 显示截图（如果有）
- 显示最终结果

**实际结果**：_（待填写）_

**测试状态**：_（待测试）_

---

## 四、测试执行计划

### 4.1 测试顺序

按照依赖关系，测试执行顺序如下：

```
第一阶段：单元测试（run_aiTest.py）
  TC-CLI-001 ~ TC-CLI-011

第二阶段：集成测试（CLI 执行功能）
  TC-INT-001 ~ TC-INT-010

第三阶段：后端服务测试
  TC-SVC-001 ~ TC-SVC-008

第四阶段：API 集成测试
  TC-API-001 ~ TC-API-006

第五阶段：端到端测试
  TC-E2E-001 ~ TC-E2E-004
```

### 4.2 测试环境准备

1. 确保 Python 环境正确
2. 确保 .env 配置正确
3. 启动 Django 后端服务
4. 启动前端服务（E2E 测试需要）

### 4.3 测试数据准备

1. 创建测试用例数据
2. 创建测试项目数据
3. 准备简单的测试任务

---

## 五、测试结果记录

### 5.1 测试汇总

| 阶段 | 总用例数 | 通过 | 失败 | 阻塞 | 通过率 |
|------|----------|------|------|------|--------|
| 单元测试 | 11 | _ | _ | _ | _ |
| 集成测试 | 10 | _ | _ | _ | _ |
| 后端服务测试 | 8 | _ | _ | _ | _ |
| API 集成测试 | 6 | _ | _ | _ | _ |
| 端到端测试 | 4 | _ | _ | _ | _ |
| **总计** | **39** | _ | _ | _ | _ |

### 5.2 问题记录

| 问题ID | 用例ID | 问题描述 | 严重程度 | 状态 |
|--------|--------|----------|----------|------|
| _ | _ | _ | _ | _ |

---

*文档维护：测试过程中实时更新测试结果和问题记录*
